# Open Embed Router - Environment Configuration
# Copy this file to .env and fill in your values

# ============================================
# Provider Configuration
# ============================================

# Provider type: "openai" or "ollama"
# - openai: OpenAI-compatible APIs (OpenAI, NanoGPT, Together AI, etc.)
# - ollama: Local Ollama server
PROVIDER=openai

# Provider base URL
# Examples:
#   OpenAI: https://api.openai.com
#   NanoGPT: https://nano-gpt.com
#   Ollama: http://localhost:11434
#   Together AI: https://api.together.xyz
#   Local LM Studio: http://localhost:1234
# Note: Do NOT include a trailing slash
PROVIDER_BASE_URL=http://localhost:11434

# API key for the provider (optional - depends on provider)
# For OpenAI: sk-your-openai-key
# For NanoGPT: sk-nano-your-key
# For Ollama: leave empty (no auth needed)
API_KEY=

# Payment header (optional - for providers using X402 payment protocol)
X_PAYMENT=

# ============================================
# Router Server Configuration
# ============================================

# Port for the router server to listen on
PORT=9000

# Number of retry attempts for failed requests
ROUTER_ATTEMPTS=3

# Initial backoff delay in milliseconds (exponential backoff)
ROUTER_BACKOFF_MS=500

# ============================================
# Logging Configuration
# ============================================

# Log level: error, warn, info, debug
LOG_LEVEL=info

# Log directory (inside container)
LOG_DIR=/app/logs

# ============================================
# Health Check Configuration
# ============================================

# Enable startup health check to verify provider connectivity
# Set to false to disable
STARTUP_CHECK=true

# Model to use for startup health check
# For Ollama: nomic-embed-text, all-minilm, etc.
# For OpenAI: text-embedding-ada-002, text-embedding-3-small
# For NanoGPT: Qwen/Qwen3-Embedding-0.6B
TEST_MODEL=nomic-embed-text

# ============================================
# API Key Authentication
# ============================================

# API Key Authentication Mode
# 
# REQUIRE_API_KEY=false (default): Public access - anyone can use the router without a key
# REQUIRE_API_KEY=true: Private access - must provide the correct API key that matches API_KEY
#
# IGNORE_INCOMING_API_KEY=true: Always use API_KEY from environment, ignoring any key sent by client
#                               (Useful when client requires a key but you want to use router's key)
#
# Examples:
# 1. Public access (no key required): REQUIRE_API_KEY=false, IGNORE_INCOMING_API_KEY=false
# 2. Private access (key required): REQUIRE_API_KEY=true, set API_KEY
# 3. Client with dummy key: IGNORE_INCOMING_API_KEY=true, set API_KEY

REQUIRE_API_KEY=false
IGNORE_INCOMING_API_KEY=false

# ============================================
# Cloudflare Tunnel Configuration (Optional)
# ============================================

# Cloudflare Tunnel Token for exposing your router to the internet with HTTPS
# Get your token by running: cloudflared tunnel create open-embed-router
# Then run: cloudflared tunnel token open-embed-router
# Leave empty to disable Cloudflare tunnel
CLOUDFLARE_TUNNEL_TOKEN=

# ============================================
# Provider Examples
# ============================================

# --- Ollama (Local) ---
# PROVIDER=ollama
# PROVIDER_BASE_URL=http://localhost:11434
# API_KEY=
# TEST_MODEL=nomic-embed-text

# --- OpenAI ---
# PROVIDER=openai
# PROVIDER_BASE_URL=https://api.openai.com
# API_KEY=sk-your-openai-key
# TEST_MODEL=text-embedding-3-small

# --- NanoGPT ---
# PROVIDER=openai
# PROVIDER_BASE_URL=https://nano-gpt.com
# API_KEY=sk-nano-your-key
# TEST_MODEL=Qwen/Qwen3-Embedding-0.6B

# --- Together AI ---
# PROVIDER=openai
# PROVIDER_BASE_URL=https://api.together.xyz
# API_KEY=your-together-key
# TEST_MODEL=togethercomputer/m2-bert-80M-8k-retrieval

# --- Local LM Studio ---
# PROVIDER=openai
# PROVIDER_BASE_URL=http://localhost:1234
# API_KEY=
# TEST_MODEL=your-loaded-model
